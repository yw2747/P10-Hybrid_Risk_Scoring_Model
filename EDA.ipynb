{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a9796-a876-4906-935a-62dba98854d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nesessary packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a47db-916c-4f44-94c3-cea662ec4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f539a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from pickle\n",
    "df = pd.read_pickle(\"Loan_status.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d71d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdee608-264f-489d-a49a-55f565d9a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file \n",
    "# df = pd.read_csv(\"Loan_status_2007-2020Q3.gzip\", on_bad_lines=\"skip\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbddff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file to pickle to save time\n",
    "# df.to_pickle(\"Loan_status.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5296ddf6",
   "metadata": {},
   "source": [
    "# Split Dataset into Training, Validation, Testing and Untouched Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Split off untouched data (10%)\n",
    "df_train_val, df_untouched = train_test_split(df, test_size=0.10, random_state=42)\n",
    "df_train_val = df_train_val.copy()  # Avoid SettingWithCopyWarning\n",
    "df_untouched = df_untouched.copy()\n",
    "df_untouched[\"set_flag\"] = 0  # Mark untouched\n",
    "\n",
    "# Step 2: Split remaining into train (50%), validation (20%), and test (20%)\n",
    "df_train, df_temp = train_test_split(df_train_val, test_size=0.40, random_state=42)\n",
    "df_train = df_train.copy()\n",
    "df_temp = df_temp.copy()\n",
    "df_train[\"set_flag\"] = 1  # Mark train\n",
    "\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.50, random_state=42)\n",
    "df_val = df_val.copy()\n",
    "df_test = df_test.copy()\n",
    "df_val[\"set_flag\"] = 2  # Mark validation\n",
    "df_test[\"set_flag\"] = 3  # Mark test\n",
    "\n",
    "# Combine all subsets back into one dataframe\n",
    "df_final = pd.concat([df_train, df_val, df_test, df_untouched], ignore_index=True)\n",
    "\n",
    "# Save as Parquet for efficient storage\n",
    "df_final.to_parquet(\"dataset_with_flags.parquet\", index=False)\n",
    "\n",
    "# Check dataset sizes\n",
    "print(f\"Training Set: {len(df_train)} rows ({len(df_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"Validation Set: {len(df_val)} rows ({len(df_val)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test Set: {len(df_test)} rows ({len(df_test)/len(df)*100:.1f}%)\")\n",
    "print(f\"Untouched Set: {len(df_untouched)} rows ({len(df_untouched)/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"Data saved with set_flag column.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de7f41-6d5e-41fc-9c03-6a519b8fa707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of training set\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b62edb",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "## 1. Drop features with > 50% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52da6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop features with > 50% missing values\n",
    "missing_percent = (df_train.isna().sum() / len(df_train))* 100\n",
    "cols_to_drop = missing_percent[missing_percent > 50].index\n",
    "print(cols_to_drop)\n",
    "df_train_dropped = df_train.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ff141-aac6-4519-bd55-83a558bb0978",
   "metadata": {},
   "source": [
    "# Categorize Predictor Variable to Loss, Good and Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80f160-1bbd-4997-b913-2fbbf8e0797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create categories for loan status\n",
    "loss = ['Charged Off', 'Does not meet the credit policy. Status:Charged Off', 'Default']\n",
    "good = ['Fully Paid', 'Current', 'Does not meet the credit policy. Status:Charged Off', 'Issued']\n",
    "df_train_dropped['loan_category'] = df_train_dropped['loan_status'].apply(lambda x: 'Loss' if x in loss else ('Good' if x in good else 'Other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4aa4f-2b98-48b0-9ae6-61de927136d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only good and loss\n",
    "df_train_dropped = df_train_dropped[df_train_dropped['loan_category'].isin(['Loss', 'Good'])]\n",
    "# convert to numerical encoding\n",
    "df_train_dropped['loan_cat_numerical'] = df_train_dropped['loan_category'].map({'Loss': 0, 'Good': 1})\n",
    "df_train_dropped['loan_cat_numerical'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with string (object) content\n",
    "string_columns = df_train_dropped.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Display the list of column names containing string content\n",
    "string_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8de152",
   "metadata": {},
   "source": [
    "# Convert String to Numeric\n",
    "\n",
    "## 1. Convert id to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert id to numeric\n",
    "df_train_dropped['id'] = pd.to_numeric(df_train_dropped['id'], errors='coerce').astype('Int64')\n",
    "# check if there'are any NAs\n",
    "df_train_dropped['id'].isna().any()\n",
    "df_train_dropped['id'].isna().sum()\n",
    "\n",
    "# show the column with NA id\n",
    "df_train_dropped[df_train_dropped['id'].isna()]\n",
    "\n",
    "# drop the entire row 39786 because it's empty\n",
    "df_train_dropped = df_train_dropped.drop(39786)\n",
    "df_train_dropped.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeafbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check result\n",
    "df_train_dropped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e95601",
   "metadata": {},
   "source": [
    "## 2. Convert emp_title to Numeric (Drop)\n",
    "\n",
    "Reasons to drop feature emp_title:\n",
    "\n",
    "1. High cardinality -- 372,749 unique values in 1,579,764 rows (~24% unique), making it difficult to extract meaningful patterns.\n",
    "2. Encoding challenge -- One-hot encoding is impractical due to excessive feature expansion; label encoding introduces arbitrary ordinal relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f9ee85-9a2e-4227-98c0-d57b0d7b50f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop emp_title column (too many distinct emp_titles)\n",
    "df_train_dropped.drop(columns=[\"emp_title\"], inplace=True)\n",
    "\n",
    "df_train_dropped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09e8016",
   "metadata": {},
   "source": [
    "## 3. Convert home_ownership to Numerical (One-hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339eb73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert home_ownership into numerical\n",
    "df_train_dropped['home_ownership'].unique()\n",
    "\n",
    "df_train_dropped['home_ownership'].isnull().sum()\n",
    "\n",
    "# perform one-hot encoding \n",
    "df_train_dropped = pd.get_dummies(df_train_dropped, columns=['home_ownership'], drop_first=False)\n",
    "\n",
    "# convert the true/false into 1/0\n",
    "home_ownership_cols = [col for col in df_train_dropped.columns if col.startswith('home_ownership_')]\n",
    "df_train_dropped[home_ownership_cols] = df_train_dropped[home_ownership_cols].astype(int)\n",
    "df_train_dropped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa9a5a",
   "metadata": {},
   "source": [
    "## 4. Convert verification_status to Numerical (One-hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d7d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert verification_status\n",
    "df_train_dropped['verification_status'].unique()\n",
    "df_train_dropped['verification_status'].isnull().sum()\n",
    "\n",
    "# one-hot encoding \n",
    "df_train_dropped = pd.get_dummies(df_train_dropped, columns=['verification_status'], drop_first=False)\n",
    "\n",
    "# convert true/false to 1/0\n",
    "verification_status_cols = [col for col in df_train_dropped.columns if col.startswith('verification_status_')]\n",
    "df_train_dropped[verification_status_cols] = df_train_dropped[verification_status_cols].astype(int)\n",
    "df_train_dropped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01928223",
   "metadata": {},
   "source": [
    "## 5. Convert issue_d to Numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert issue_d\n",
    "df_train_dropped['issue_d'].head()\n",
    "\n",
    "df_train_dropped['issue_d'].isnull().sum()\n",
    "\n",
    "df_train_dropped['loan_status'].unique()\n",
    "\n",
    "# Convert issue_d to datetime\n",
    "df_train_dropped['issue_d'] = pd.to_datetime(df_train_dropped['issue_d'], format='%b-%Y')\n",
    "# Group by month-year and calculate the proportion of \"loss\" loans\n",
    "loss_rate = df_train_dropped.groupby(df_train_dropped['issue_d'].dt.to_period('Y'))['loan_category'].apply(lambda x: (x == 'Loss').mean())\n",
    "\n",
    "# Plot the trend\n",
    "plt.figure(figsize=(14, 6))\n",
    "#x_labels = loss_rate.index.astype(str)[::4]  # Show every 4th label\n",
    "plt.plot(loss_rate.index.astype(str), loss_rate.values, marker='o', linestyle='-')\n",
    "#plt.xticks(ticks=x_labels, rotation=45)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Loan Issue Date (Year)\")\n",
    "plt.ylabel(\"Proportion of Loss Loans\")\n",
    "plt.title(\"Trend of Loan Default Rate Over Time (Yearly)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b214273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert issue_d to an Ordinal Feature\n",
    "df_train_dropped['issue_d_ordinal'] = df_train_dropped['issue_d'].dt.year - df_train_dropped['issue_d'].dt.year.min()\n",
    "#df_train_dropped.drop(columns=['issue_d'], inplace=True)  # Drop original datetime column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a19d525",
   "metadata": {},
   "source": [
    "## 6. Convert url to Numeric (Drop)\n",
    "Reason to drop url: \n",
    "1. url unaccessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loanDetails that requires investor account to login (Unaccessible)\n",
    "## Drop column\n",
    "df_train_dropped.drop(columns=[\"url\"], inplace=True)\n",
    "\n",
    "df_train_dropped.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10629859",
   "metadata": {},
   "source": [
    "## 7. Convert Term to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55091bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature Term and convert to numeric\n",
    "df_train_dropped[\"term\"].unique()\n",
    "\n",
    "# Convert  numeric \n",
    "df_train_dropped[\"term\"] = df_train_dropped[\"term\"].str.extract(\"(\\d+)\").astype(float)\n",
    "\n",
    "# Plot distribution of loan terms\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df_train_dropped[\"term\"])\n",
    "plt.title(\"Distribution of Loan Terms\")\n",
    "plt.xlabel(\"Loan Term (Months)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9ce3da",
   "metadata": {},
   "source": [
    "## 8. Convert int_rate to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature int_rate and convert to numeric\n",
    "df_train_dropped[\"int_rate\"].unique()\n",
    "\n",
    "# Plot distribution of int_rate\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df_train_dropped[\"int_rate\"])\n",
    "plt.title(\"Distribution of int_rate\")\n",
    "plt.xlabel(\"int_rate)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Convert\n",
    "df_train_dropped[\"int_rate\"] = df_train_dropped[\"int_rate\"].replace(\"nan\", np.nan)\n",
    "df_train_dropped[\"int_rate\"] = df_train_dropped[\"int_rate\"].str.replace(\"%\", \"\").astype(float) / 100\n",
    "df_train_dropped[\"int_rate\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075dc2b",
   "metadata": {},
   "source": [
    "## 9. Convert sub_grade to Numeric (Drop grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607543c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature grade and subgrade\n",
    "df_train_dropped[\"grade\"].unique()\n",
    "df_train_dropped[\"sub_grade\"].unique()\n",
    "\n",
    "# Possible feature engineering: Combine into one feature A=1, B=2, C=3, D=4, E=5, F=6, G=7 (Smaller number has lower risk)===> \n",
    "# Use only converted sub_grade, drop feature grade\n",
    "df_train_dropped = df_train_dropped.drop([\"grade\"], axis=1)\n",
    "\n",
    "# Define base values for grades (lower = better credit, higher = higher risk)\n",
    "grade_mapping = {\"A\" :1, \"B\" : 2, \"C\" : 3, \"D\" : 4, \"E\" : 5, \"F\" : 6, \"G\" : 7}\n",
    "\n",
    "# Convert nan to np.nan\n",
    "df_train_dropped[\"sub_grade\"] = df_train_dropped[\"sub_grade\"].replace(\"nan\", np.nan)\n",
    "\n",
    "# Check if has nan valus (1 nan)\n",
    "df_train_dropped[\"sub_grade\"].isna().sum()\n",
    "\n",
    "# Check if the original \"nan\" value converted to np.nan (All converted)\n",
    "print((df_train_dropped[\"sub_grade\"] == \"nan\").sum())\n",
    "\n",
    "# Plot the distribution of sub_grade with proper ranking from low to high\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(y=df_train_dropped[\"sub_grade\"], order=sorted(df_train_dropped[\"sub_grade\"].unique()), palette=\"Blues_r\")\n",
    "plt.title(\"Distribution of Sub Grade (Ranked Low to High)\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Sub Grade\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Convert sub_grade into an ordered numeric feature where A1 is lowest risk and G5 is highest risk\n",
    "df_train_dropped[\"sub_grade\"] = df_train_dropped[\"sub_grade\"].apply(lambda x: grade_mapping[str(x)[0]] * 10 + int(str(x)[1]) if pd.notna(x) else np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4186b7",
   "metadata": {},
   "source": [
    "## 10. Convert emp_length to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f77a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature emp_length\n",
    "df_train_dropped[\"emp_length\"].unique()\n",
    "\n",
    "def convert_emp_length(emp):\n",
    "    if pd.isna(emp):  # Handle missing values\n",
    "        return np.nan\n",
    "    if emp == \"10+ years\":\n",
    "        return 10\n",
    "    elif emp == \"< 1 year\":\n",
    "        return 0\n",
    "    else:\n",
    "        return int(emp.split()[0])  # Extract the number from \"X years\"\n",
    "## Check below for convertion criterion\n",
    "\n",
    "\n",
    "## Convert emp_length to numeric\n",
    "df_train_dropped[\"emp_length\"] = df_train_dropped[\"emp_length\"].apply(convert_emp_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handeling 'purpose', 'title', 'zip_code', 'addr_state',\n",
    "\n",
    "df_train_dropped[\"purpose\"].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c9279e",
   "metadata": {},
   "source": [
    "## 11. Convert Purpose to Numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d11977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"purpose\" from string to numeric\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'purpose' column\n",
    "df_train_dropped[\"purpose\"] = le.fit_transform(df_train_dropped[\"purpose\"])\n",
    "\n",
    "# View unique mappings\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26761c",
   "metadata": {},
   "source": [
    "## 12.Convert Title to Numeric (Drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2746072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'title' from strings to numeric (Since similar to \"Purpose, drop it\")\n",
    "num_unique_titles = df_train_dropped[\"title\"].nunique()\n",
    "title_counts = df_train_dropped[\"title\"].value_counts()\n",
    "purpose_counts = df_train_dropped[\"purpose\"].value_counts()\n",
    "\n",
    "df_train_dropped = df_train_dropped.drop(columns=[\"title\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e37ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c98a88ee",
   "metadata": {},
   "source": [
    "## 13. Convert zip_code, addr_state to Numeric(Drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5537422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"zip_code\" to numeric\n",
    "df_train_dropped[\"zip_code\"].unique()\n",
    "\n",
    "# Drop zip_code\n",
    "df_train_dropped = df_train_dropped.drop(columns=[\"zip_code\"])\n",
    "\n",
    "# Drop \"addr_state\"\n",
    "df_train_dropped[\"addr_state\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243f606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check df after column dropping\n",
    "df_train_dropped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e5c9c",
   "metadata": {},
   "source": [
    "## 14. Convert hardship_flag to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae11f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'N' to 0 and 'Y' to 1\n",
    "df_train_dropped[\"hardship_flag\"] = df_train_dropped[\"hardship_flag\"].map({\n",
    "                                                                          \"N\": 0, \"Y\": 1})\n",
    "\n",
    "df_train_dropped[\"hardship_flag\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db866b",
   "metadata": {},
   "source": [
    "## 15. Convert debt_settlement_flag to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84caf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'N' to 0 and 'Y' to 1\n",
    "df_train_dropped[\"debt_settlement_flag\"] = df_train_dropped[\"debt_settlement_flag\"].map({\n",
    "                                                                                        \"N\": 0, \"Y\": 1})\n",
    "\n",
    "df_train_dropped[\"debt_settlement_flag\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118044fb",
   "metadata": {},
   "source": [
    "## 16. Convert application_type to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716ac432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'Individual' to 0 and 'Joint App' to 1\n",
    "df_train_dropped[\"application_type\"] = df_train_dropped[\"application_type\"].map(\n",
    "    {\"Individual\": 0, \"Joint App\": 1})\n",
    "\n",
    "df_train_dropped[\"application_type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16c54e",
   "metadata": {},
   "source": [
    "## 17. Convert last_credit_pull_d to Numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adccd25",
   "metadata": {},
   "source": [
    "Convert date to a numeric measure of recency in days (reference date - credit pull date; smaller is worse)\n",
    "\n",
    "Reference Date: September 30, 2020 because the dataset appears to be as recent as Q3 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf1a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dropped[\"last_credit_pull_d\"] = pd.to_datetime(\n",
    "    df_train_dropped[\"last_credit_pull_d\"])\n",
    "\n",
    "# Define reference date as the end of Q3 2020\n",
    "reference_date = pd.to_datetime(\"2020-09-30\")\n",
    "\n",
    "df_train_dropped[\"last_credit_pull_d\"] = (\n",
    "    reference_date - df_train_dropped[\"last_credit_pull_d\"]).dt.days\n",
    "\n",
    "df_train_dropped[\"last_credit_pull_d\"].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

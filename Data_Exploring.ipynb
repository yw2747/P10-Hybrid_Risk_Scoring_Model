{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a9796-a876-4906-935a-62dba98854d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a47db-916c-4f44-94c3-cea662ec4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f539a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from pickle\n",
    "df = pd.read_pickle(\"Loan_status.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdee608-264f-489d-a49a-55f565d9a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file \n",
    "# df = pd.read_csv(\"Loan_status_2007-2020Q3.gzip\", on_bad_lines=\"skip\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbddff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file to pickle to save time\n",
    "# df.to_pickle(\"Loan_status.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Split off untouched data (10%)\n",
    "df_train_val, df_untouched = train_test_split(df, test_size=0.10, random_state=42)\n",
    "df_train_val = df_train_val.copy()  # Avoid SettingWithCopyWarning\n",
    "df_untouched = df_untouched.copy()\n",
    "df_untouched[\"set_flag\"] = 0  # Mark untouched\n",
    "\n",
    "# Step 2: Split remaining into train (50%), validation (20%), and test (20%)\n",
    "df_train, df_temp = train_test_split(df_train_val, test_size=0.40, random_state=42)\n",
    "df_train = df_train.copy()\n",
    "df_temp = df_temp.copy()\n",
    "df_train[\"set_flag\"] = 1  # Mark train\n",
    "\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.50, random_state=42)\n",
    "df_val = df_val.copy()\n",
    "df_test = df_test.copy()\n",
    "df_val[\"set_flag\"] = 2  # Mark validation\n",
    "df_test[\"set_flag\"] = 3  # Mark test\n",
    "\n",
    "# Combine all subsets back into one dataframe\n",
    "df_final = pd.concat([df_train, df_val, df_test, df_untouched], ignore_index=True)\n",
    "\n",
    "# Save as Parquet for efficient storage\n",
    "df_final.to_parquet(\"dataset_with_flags.parquet\", index=False)\n",
    "\n",
    "# Check dataset sizes\n",
    "print(f\"Training Set: {len(df_train)} rows ({len(df_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"Validation Set: {len(df_val)} rows ({len(df_val)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test Set: {len(df_test)} rows ({len(df_test)/len(df)*100:.1f}%)\")\n",
    "print(f\"Untouched Set: {len(df_untouched)} rows ({len(df_untouched)/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"Data saved with set_flag column.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de7f41-6d5e-41fc-9c03-6a519b8fa707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of training set\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52da6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop features with > 50% missing values\n",
    "missing_percent = (df_train.isna().sum() / len(df_train))* 100\n",
    "cols_to_drop = missing_percent[missing_percent > 50].index\n",
    "print(cols_to_drop)\n",
    "df_train_dropped = df_train.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with string (object) content\n",
    "string_columns = df_train_dropped.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Display the list of column names containing string content\n",
    "string_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loanDetails that requires investor account to login (Unaccessible)\n",
    "## Drop column\n",
    "df_train_dropped.drop(columns=[\"url\"], inplace=True)\n",
    "\n",
    "df_train_dropped.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f9ee85-9a2e-4227-98c0-d57b0d7b50f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop emp_title column (too many distinct emp_titles)\n",
    "df_train_dropped.drop(columns=[\"emp_title\"], inplace=True)\n",
    "\n",
    "df_train_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55091bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature Term and convert to numeric\n",
    "df_train_dropped[\"term\"].unique()\n",
    "\n",
    "# Convert  numeric (Remove comment to use)\n",
    "df_train_dropped[\"term\"] = df_train_dropped[\"term\"].str.extract(\"(\\d+)\").astype(float)\n",
    "\n",
    "# Plot distribution of loan terms\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df_train_dropped[\"term\"])\n",
    "plt.title(\"Distribution of Loan Terms\")\n",
    "plt.xlabel(\"Loan Term (Months)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature int_rate and convert to numeric\n",
    "df_train_dropped[\"int_rate\"].unique()\n",
    "\n",
    "# Plot distribution of int_rate\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df_train_dropped[\"int_rate\"])\n",
    "plt.title(\"Distribution of int_rate\")\n",
    "plt.xlabel(\"int_rate)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "df_train_dropped[\"int_rate\"] = df_train_dropped[\"int_rate\"].replace(\"nan\", np.nan)\n",
    "df_train_dropped[\"int_rate\"] = df_train_dropped[\"int_rate\"].str.replace(\"%\", \"\").astype(float) / 100\n",
    "df_train_dropped[\"int_rate\"].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607543c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature grade and subgrade\n",
    "df_train_dropped[\"grade\"].unique()\n",
    "df_train_dropped[\"sub_grade\"].unique()\n",
    "\n",
    "# Possible feature engineering: Combine into one feature A=1, B=2, C=3, D=4, E=5, F=6, G=7 (Smaller number has lower risk)===> \n",
    "# Use only converted sub_grade, drop feature grade\n",
    "df_train_dropped = df_train_dropped.drop([\"grade\"], axis=1)\n",
    "\n",
    "# Define base values for grades (lower = better credit, higher = higher risk)\n",
    "grade_mapping = {\"A\" :1, \"B\" : 2, \"C\" : 3, \"D\" : 4, \"E\" : 5, \"F\" : 6, \"G\" : 7}\n",
    "\n",
    "# Convert nan to np.nan\n",
    "df_train_dropped[\"sub_grade\"] = df_train_dropped[\"sub_grade\"].replace(\"nan\", np.nan)\n",
    "\n",
    "\n",
    "\n",
    "# Convert sub_grade into an ordered numeric feature where A1 is lowest risk and G5 is highest risk\n",
    "df_train_dropped[\"sub_grade\"] = df_train_dropped[\"sub_grade\"].apply(lambda x: grade_mapping[str(x)[0]] * 10 + int(str(x)[1]) if pd.notna(x) else np.nan)\n",
    "\n",
    "# Check below for encoding matchup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if has nan valus (1 nan)\n",
    "df_train_dropped[\"sub_grade\"].isna().sum()\n",
    "\n",
    "# Check if the original \"nan\" value converted to np.nan (All converted)\n",
    "print((df_train_dropped[\"sub_grade\"] == \"nan\").sum())\n",
    "\n",
    "# Plot the distribution of sub_grade with proper ranking from low to high\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(y=df_train_dropped[\"sub_grade\"], order=sorted(df_train_dropped[\"sub_grade\"].unique()), palette=\"Blues_r\")\n",
    "plt.title(\"Distribution of Sub Grade (Ranked Low to High)\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Sub Grade\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f77a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature emp_length\n",
    "df_train_dropped[\"emp_length\"].unique()\n",
    "\n",
    "def convert_emp_length(emp):\n",
    "    if pd.isna(emp):  # Handle missing values\n",
    "        return np.nan\n",
    "    if emp == \"10+ years\":\n",
    "        return 10\n",
    "    elif emp == \"< 1 year\":\n",
    "        return 0\n",
    "    else:\n",
    "        return int(emp.split()[0])  # Extract the number from \"X years\"\n",
    "## Check below for convertion criterion\n",
    "\n",
    "\n",
    "## Convert emp_length to numeric\n",
    "df_train_dropped[\"emp_length_numeric\"] = df_train_dropped[\"emp_length\"].apply(convert_emp_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eadd3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original emp_length\n",
    "df_train_dropped.drop(columns = [\"emp_length\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handeling 'purpose', 'title', 'zip_code', 'addr_state',\n",
    "\n",
    "df_train_dropped[\"purpose\"].unique()\n",
    "df_train_dropped[\"purpose\"].value_counts()\n",
    "print(df_train_dropped[\"loan_status\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5817e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping\n",
    "loan_status_map = {\n",
    "    \"Fully Paid\": 1,\n",
    "    \"Does not meet the credit policy. Status:Fully Paid\": 1,\n",
    "    \"Charged Off\": 0,\n",
    "    \"Default\": 0,\n",
    "    \"Late (31-120 days)\": 0,\n",
    "    \"Late (16-30 days)\": 0,\n",
    "    \"Does not meet the credit policy. Status:Charged Off\": 0\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "df_train_dropped[\"loan_status\"] = df_train_dropped[\"loan_status\"].map(loan_status_map)\n",
    "\n",
    "# Remove rows where loan_status is NaN (e.g., 'Issued' or unknown statuses)\n",
    "df_train_dropped = df_train_dropped.dropna(subset=[\"loan_status\"])\n",
    "\n",
    "# Convert to integer type\n",
    "df_train_dropped[\"loan_status\"] = df_train_dropped[\"loan_status\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d11977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"purpose\" from string to numeric\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'purpose' column\n",
    "df_train_dropped[\"purpose_encoded\"] = le.fit_transform(df_train_dropped[\"purpose\"])\n",
    "\n",
    "# View unique mappings\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2746072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'title' from strings to numeric (Since similar to \"Purpose, drop it\")\n",
    "num_unique_titles = df_train_dropped[\"title\"].nunique()\n",
    "title_counts = df_train_dropped[\"title\"].value_counts()\n",
    "purpose_counts = df_train_dropped[\"purpose\"].value_counts()\n",
    "\n",
    "df_train_dropped = df_train_dropped.drop(columns=[\"title\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"zip_code\" to numeric\n",
    "df_train_dropped[\"zip_code\"].unique()\n",
    "\n",
    "# Drop zip_code\n",
    "df_train_dropped = df_train_dropped.drop(columns=[\"zip_code\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \"addr_state\"\n",
    "df_train_dropped[\"addr_state\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check df after column dropping\n",
    "df_train_dropped.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

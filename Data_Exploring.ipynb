{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a9796-a876-4906-935a-62dba98854d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a47db-916c-4f44-94c3-cea662ec4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdee608-264f-489d-a49a-55f565d9a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file \n",
    "df = pd.read_csv(\"Loan_status_2007-2020Q3.gzip\", on_bad_lines=\"skip\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbddff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file to pickle to save time\n",
    "df.to_pickle(\"Loan_status.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into sections\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Split off untouched data (10%)\n",
    "df_train_val, df_untouched = train_test_split(df, test_size=0.10, random_state=42)\n",
    "\n",
    "# Step 2: Split remaining into train (50%), validation (20%), and test (20%)\n",
    "df_train, df_temp = train_test_split(df_train_val, test_size=0.40, random_state=42)  # 50% training, 40% left for val+test\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.50, random_state=42)  # Split equally into validation & test\n",
    "\n",
    "# Check dataset sizes\n",
    "print(f\"Training Set: {len(df_train)} rows ({len(df_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"Validation Set: {len(df_val)} rows ({len(df_val)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test Set: {len(df_test)} rows ({len(df_test)/len(df)*100:.1f}%)\")\n",
    "print(f\"Untouched Set: {len(df_untouched)} rows ({len(df_untouched)/len(df)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f9ee85-9a2e-4227-98c0-d57b0d7b50f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check content of url\n",
    "## loanDetails that requires investor account to login (Unaccessible)\n",
    "## Drop column\n",
    "# pd.set_option(\"display.max_colwidth\", None)\n",
    "# df_train[\"url\"].head()\n",
    "\n",
    "df_train[\"emp_title\"].unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de7f41-6d5e-41fc-9c03-6a519b8fa707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of training set\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52da6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop features with > 50% missing values\n",
    "missing_percent = (df_train.isna().sum() / len(df_train))* 100\n",
    "cols_to_drop = missing_percent[missing_percent > 50].index\n",
    "print(cols_to_drop)\n",
    "df_train_dropped = df_train.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loanDetails that requires investor account to login (Unaccessible)\n",
    "## Drop column\n",
    "# df_train_dropped.drop(columns=[\"url\"], inplace=True)\n",
    "\n",
    "df_train_dropped.head()\n",
    "# Identify columns with string (object) content\n",
    "string_columns = df_train_dropped.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Display the list of column names containing string content\n",
    "string_columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55091bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature Term and convert to numeric\n",
    "df_train_dropped[\"term\"].unique()\n",
    "\n",
    "# Convert  numeric (Remove comment to use)\n",
    "df_train_dropped[\"term\"] = df_train_dropped[\"term\"].str.extract(\"(\\d+)\").astype(float)\n",
    "\n",
    "# Plot distribution of loan terms\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df_train_dropped[\"term\"])\n",
    "plt.title(\"Distribution of Loan Terms\")\n",
    "plt.xlabel(\"Loan Term (Months)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature int_rate and convert to numeric\n",
    "df_train_dropped[\"int_rate\"].unique()\n",
    "\n",
    "# Plot distribution of int_rate\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df_train_dropped[\"int_rate\"])\n",
    "plt.title(\"Distribution of int_rate\")\n",
    "plt.xlabel(\"int_rate)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "df_train_dropped[\"int_rate\"] = df_train_dropped[\"int_rate\"].replace(\"nan\", np.nan)\n",
    "df_train_dropped[\"int_rate\"] = df_train_dropped[\"int_rate\"].str.replace(\"%\", \"\").astype(float) / 100\n",
    "df_train_dropped[\"int_rate\"].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607543c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature grade and subgrade\n",
    "df_train_dropped[\"grade\"].unique()\n",
    "df_train_dropped[\"sub_grade\"].unique()\n",
    "\n",
    "# Possible feature engineering: Combine into one feature A=1, B=2, C=3, D=4, E=5, F=6, G=7 (Smaller number has lower risk)===> \n",
    "# Use only converted sub_grade, drop feature grade\n",
    "df_train_dropped = df_train_dropped.drop([\"grade\"], axis=1)\n",
    "\n",
    "# Define base values for grades (lower = better credit, higher = higher risk)\n",
    "grade_mapping = {\"A\" :1, \"B\" : 2, \"C\" : 3, \"D\" : 4, \"E\" : 5, \"F\" : 6, \"G\" : 7}\n",
    "\n",
    "# Convert nan to np.nan\n",
    "df_train_dropped[\"sub_grade\"] = df_train_dropped[\"sub_grade\"].replace(\"nan\", np.nan)\n",
    "\n",
    "\n",
    "\n",
    "# Convert sub_grade into an ordered numeric feature where A1 is lowest risk and G5 is highest risk\n",
    "df_train_dropped[\"sub_grade\"] = df_train_dropped[\"sub_grade\"].apply(lambda x: grade_mapping[str(x)[0]] * 10 + int(str(x)[1]) if pd.notna(x) else np.nan)\n",
    "\n",
    "# Check below for encoding matchup\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6666eaff",
   "metadata": {},
   "source": [
    "![Image Description](Encode_subgrade.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if has nan valus (1 nan)\n",
    "df_train_dropped[\"sub_grade\"].isna().sum()\n",
    "\n",
    "# Check if the original \"nan\" value converted to np.nan (All converted)\n",
    "print((df_train_dropped[\"sub_grade\"] == \"nan\").sum())\n",
    "\n",
    "# Plot the distribution of sub_grade with proper ranking from low to high\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(y=df_train_dropped[\"sub_grade\"], order=sorted(df_train_dropped[\"sub_grade\"].unique()), palette=\"Blues_r\")\n",
    "plt.title(\"Distribution of Sub Grade (Ranked Low to High)\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Sub Grade\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5579028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f77a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature emp_length\n",
    "df_train_dropped[\"emp_length\"].unique()\n",
    "\n",
    "def convert_emp_length(emp):\n",
    "    if pd.isna(emp):  # Handle missing values\n",
    "        return np.nan\n",
    "    if emp == \"10+ years\":\n",
    "        return 10\n",
    "    elif emp == \"< 1 year\":\n",
    "        return 0\n",
    "    else:\n",
    "        return int(emp.split()[0])  # Extract the number from \"X years\"\n",
    "## Check below for convertion criterion\n",
    "\n",
    "\n",
    "## Convert emp_length to numeric\n",
    "df_train_dropped[\"emp_length_numeric\"] = df_train_dropped[\"emp_length\"].apply(convert_emp_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd0f4ac1",
   "metadata": {},
   "source": [
    "![Image Description](Emp_length_Convertion.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5d007-4b06-4c19-9e47-761b8d79db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bddefc5-867f-4004-ba05-2ed464aa2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percent = (df.isna().sum() / len(df))* 100\n",
    "cols_to_drop = missing_percent[missing_percent > 50].index\n",
    "print(cols_to_drop)\n",
    "df = df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a688ab-c1ad-4f10-a379-e6b2e0946e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac2765-7f87-46d4-ab00-6fb35f844cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4336ac42-5ed4-4961-a7a6-3311b03bd855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loan_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315db5de-27f5-4865-89d8-8ea85913353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce1e93a-4b72-4b78-af70-0e2e5d43ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check numerical features\n",
    "num_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "print(num_cols)\n",
    "\n",
    "\n",
    "# Count missing values for each column\n",
    "print(df[['loan_amnt', 'funded_amnt', 'funded_amnt_inv']].isna().sum())\n",
    "\n",
    "# Count rows where any of these are missing (Total rows with at least one missing value: 1)\n",
    "missing_rows = df[df[['loan_amnt', 'funded_amnt', 'funded_amnt_inv']].isna().any(axis=1)]\n",
    "print(f\"Total rows with at least one missing value: {len(missing_rows)}\")\n",
    "\n",
    "# Drop that row\n",
    "df = df.dropna(subset=['loan_amnt', 'funded_amnt', 'funded_amnt_inv'], how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599a427-5e66-442d-9c9d-d72b248b8189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing loan_amnt/funded_amnt/funded_amnt_inv values\n",
    "\n",
    "## If funded_amnt_inv is Missing, Fill with funded_amnt\n",
    "df_dropped[\"funded_amnt_inv\"].fillna(df_dropped[\"funded_amnt\"], inplace=True)\n",
    "\n",
    "## If funded_amnt is Missing, Fill with loan_amnt\n",
    "df_dropped[\"funded_amnt\"].fillna(df_dropped[\"loan_amnt\"], inplace=True)\n",
    "\n",
    "## If loan_amnt is Missing, Fill with funded_amnt\n",
    "df_dropped[\"loan_amnt\"].fillna(df_dropped[\"funded_amnt\"], inplace=True)\n",
    "\n",
    "\n",
    "missing_loan_counts = df_dropped[['loan_amnt', 'funded_amnt', 'funded_amnt_inv']].isna().sum()\n",
    "print(missing_loan_counts)\n",
    "## All rows have one of the three values\n",
    "\n",
    "## Check correlation among these 3 features\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr_matrix = df[['loan_amnt', 'funded_amnt', 'funded_amnt_inv']].corr()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Between Loan Features\")\n",
    "plt.show()\n",
    "## All three features are highly correlated (~1.00 correlation):\n",
    "## Potential actions: 1. Drop two of them, leave one.  \n",
    "# 2. Create derived features (like funding_ratio and investor_confidence) other than use original ones\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87a0bb1b",
   "metadata": {},
   "source": [
    "![Image Description](Three_Ratios.png)\n",
    "ChatGPT suggests using these three new features instead of original ones. Let xgboost choose which newly created feature to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped[\"funding_ratio\"] = df_dropped[\"funded_amnt\"] / df_dropped[\"loan_amnt\"] ## Funding Ratio (Lender Confidence)\n",
    "\n",
    "df_dropped[\"investor_confidence\"] = df_dropped[\"funded_amnt_inv\"] / df_dropped[\"funded_amnt\"] ## Investor Confidence Ratio\n",
    "\n",
    "df_dropped[\"loan_to_investor_funded\"] = df_dropped[\"loan_amnt\"] / df_dropped[\"funded_amnt_inv\"]\n",
    "\n",
    "df_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f096023",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature: home_ownership\n",
    "df[\"home_ownership\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7deef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the distribution of home_ownership categories\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x=\"home_ownership\", order=df[\"home_ownership\"].value_counts().index)\n",
    "plt.title(\"Distribution of Home Ownership Categories\")\n",
    "plt.xlabel(\"Home Ownership Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
